{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FEATURE_PATH = r'../../Datasets/train_features.csv'\n",
    "TRAIN_LABEL_PATH = r'../../Datasets/train_labels.csv'\n",
    "TEST_PATH = r'../../Datasets/test_features.csv'\n",
    "SAMPLE_SUBMISSION_PATH = r\"../../Datasets/submission_format.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feature = pd.read_csv(TRAIN_FEATURE_PATH)\n",
    "df_train_label = pd.read_csv(TRAIN_LABEL_PATH)\n",
    "df_test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tahun_kelahiran</th>\n",
       "      <th>pendidikan</th>\n",
       "      <th>status_pernikahan</th>\n",
       "      <th>pendapatan</th>\n",
       "      <th>jumlah_anak_balita</th>\n",
       "      <th>jumlah_anak_remaja</th>\n",
       "      <th>terakhir_belanja</th>\n",
       "      <th>belanja_buah</th>\n",
       "      <th>belanja_daging</th>\n",
       "      <th>belanja_ikan</th>\n",
       "      <th>belanja_kue</th>\n",
       "      <th>pembelian_diskon</th>\n",
       "      <th>pembelian_web</th>\n",
       "      <th>pembelian_toko</th>\n",
       "      <th>keluhan</th>\n",
       "      <th>tanggal_menjadi_anggota</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>Sarjana</td>\n",
       "      <td>Rencana Menikah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50575.0</td>\n",
       "      <td>260967.0</td>\n",
       "      <td>50575.0</td>\n",
       "      <td>20230.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>Sarjana</td>\n",
       "      <td>Rencana Menikah</td>\n",
       "      <td>84063000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6069.0</td>\n",
       "      <td>44506.0</td>\n",
       "      <td>80920.0</td>\n",
       "      <td>20230.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1966</td>\n",
       "      <td>Sarjana</td>\n",
       "      <td>Menikah</td>\n",
       "      <td>127532564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>117611.0</td>\n",
       "      <td>265460.0</td>\n",
       "      <td>96341.0</td>\n",
       "      <td>145573.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1961</td>\n",
       "      <td>Magister</td>\n",
       "      <td>Rencana Menikah</td>\n",
       "      <td>165579620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>206346.0</td>\n",
       "      <td>1613901.0</td>\n",
       "      <td>27725.0</td>\n",
       "      <td>125868.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970</td>\n",
       "      <td>Sarjana</td>\n",
       "      <td>Rencana Menikah</td>\n",
       "      <td>117703159.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>90563.0</td>\n",
       "      <td>311757.0</td>\n",
       "      <td>40358.0</td>\n",
       "      <td>33875.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3812</th>\n",
       "      <td>1955</td>\n",
       "      <td>Magister</td>\n",
       "      <td>Menikah</td>\n",
       "      <td>78199470.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6069.0</td>\n",
       "      <td>25977.0</td>\n",
       "      <td>3856.0</td>\n",
       "      <td>5784.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>1947</td>\n",
       "      <td>Doktor</td>\n",
       "      <td>Rencana Menikah</td>\n",
       "      <td>109306000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50575.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>1974</td>\n",
       "      <td>Magister</td>\n",
       "      <td>Menikah</td>\n",
       "      <td>104621000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>62713.0</td>\n",
       "      <td>8092.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-11-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3815</th>\n",
       "      <td>1957</td>\n",
       "      <td>SMA</td>\n",
       "      <td>Rencana Menikah</td>\n",
       "      <td>110850000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>18207.0</td>\n",
       "      <td>70805.0</td>\n",
       "      <td>24276.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>1961</td>\n",
       "      <td>Sarjana</td>\n",
       "      <td>Menikah</td>\n",
       "      <td>130512000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>329749.0</td>\n",
       "      <td>600831.0</td>\n",
       "      <td>420784.0</td>\n",
       "      <td>161840.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-01-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3817 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tahun_kelahiran pendidikan status_pernikahan   pendapatan  \\\n",
       "0                1979    Sarjana   Rencana Menikah          NaN   \n",
       "1                1950    Sarjana   Rencana Menikah   84063000.0   \n",
       "2                1966    Sarjana           Menikah  127532564.0   \n",
       "3                1961   Magister   Rencana Menikah  165579620.0   \n",
       "4                1970    Sarjana   Rencana Menikah  117703159.0   \n",
       "...               ...        ...               ...          ...   \n",
       "3812             1955   Magister           Menikah   78199470.0   \n",
       "3813             1947     Doktor   Rencana Menikah  109306000.0   \n",
       "3814             1974   Magister           Menikah  104621000.0   \n",
       "3815             1957        SMA   Rencana Menikah  110850000.0   \n",
       "3816             1961    Sarjana           Menikah  130512000.0   \n",
       "\n",
       "      jumlah_anak_balita  jumlah_anak_remaja  terakhir_belanja  belanja_buah  \\\n",
       "0                    0.0                 1.0               NaN       50575.0   \n",
       "1                    NaN                 NaN              70.0        6069.0   \n",
       "2                    0.0                 0.0              45.0      117611.0   \n",
       "3                    0.0                 0.0              90.0      206346.0   \n",
       "4                    1.0                 1.0              78.0       90563.0   \n",
       "...                  ...                 ...               ...           ...   \n",
       "3812                 0.0                 0.0              33.0        6069.0   \n",
       "3813                 0.0                 1.0              44.0           0.0   \n",
       "3814                 0.0                 2.0              68.0        2023.0   \n",
       "3815                 1.0                 1.0              67.0       18207.0   \n",
       "3816                 0.0                 0.0              70.0      329749.0   \n",
       "\n",
       "      belanja_daging  belanja_ikan  belanja_kue  pembelian_diskon  \\\n",
       "0           260967.0       50575.0      20230.0               2.0   \n",
       "1            44506.0       80920.0      20230.0               9.0   \n",
       "2           265460.0       96341.0     145573.0               1.0   \n",
       "3          1613901.0       27725.0     125868.0               0.0   \n",
       "4           311757.0       40358.0      33875.0               7.0   \n",
       "...              ...           ...          ...               ...   \n",
       "3812         25977.0        3856.0       5784.0               5.0   \n",
       "3813         50575.0           NaN          0.0               3.0   \n",
       "3814         62713.0        8092.0          0.0               7.0   \n",
       "3815         70805.0       24276.0          NaN               4.0   \n",
       "3816        600831.0      420784.0     161840.0               3.0   \n",
       "\n",
       "      pembelian_web  pembelian_toko  keluhan tanggal_menjadi_anggota  \n",
       "0               2.0             5.0      0.0              2014-05-05  \n",
       "1               6.0             4.0      0.0              2013-03-17  \n",
       "2               1.0             7.0      0.0                     NaN  \n",
       "3               7.0             8.0      0.0                     NaN  \n",
       "4               6.0             5.0      0.0                     NaN  \n",
       "...             ...             ...      ...                     ...  \n",
       "3812            1.0             0.0      0.0                     NaN  \n",
       "3813            6.0             3.0      0.0              2014-06-09  \n",
       "3814            5.0             7.0      0.0              2013-11-07  \n",
       "3815            5.0             4.0      0.0              2013-06-30  \n",
       "3816            7.0            15.0      0.0              2014-01-25  \n",
       "\n",
       "[3817 rows x 16 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3817 entries, 0 to 3816\n",
      "Data columns (total 16 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   tahun_kelahiran          3817 non-null   int64  \n",
      " 1   pendidikan               3628 non-null   object \n",
      " 2   status_pernikahan        3605 non-null   object \n",
      " 3   pendapatan               3627 non-null   float64\n",
      " 4   jumlah_anak_balita       3627 non-null   float64\n",
      " 5   jumlah_anak_remaja       3613 non-null   float64\n",
      " 6   terakhir_belanja         3645 non-null   float64\n",
      " 7   belanja_buah             3636 non-null   float64\n",
      " 8   belanja_daging           3639 non-null   float64\n",
      " 9   belanja_ikan             3624 non-null   float64\n",
      " 10  belanja_kue              3603 non-null   float64\n",
      " 11  pembelian_diskon         3639 non-null   float64\n",
      " 12  pembelian_web            3652 non-null   float64\n",
      " 13  pembelian_toko           3648 non-null   float64\n",
      " 14  keluhan                  3621 non-null   float64\n",
      " 15  tanggal_menjadi_anggota  1065 non-null   object \n",
      "dtypes: float64(12), int64(1), object(3)\n",
      "memory usage: 477.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train_feature.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3817 entries, 0 to 3816\n",
      "Data columns (total 1 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   jumlah_promosi  3817 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 29.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_train_label.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datascience.stackexchange.com/questions/26581/should-i-impute-target-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop tanggal_menjadi_anggota\n",
    "df_train_feature = df_train_feature.drop(columns={'tanggal_menjadi_anggota'})\n",
    "df_test = df_test.drop(columns={'tanggal_menjadi_anggota'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_train_feature['pendidikan_encoded'] = label_encoder.fit_transform(df_train_feature['pendidikan'])\n",
    "df_train_feature =df_train_feature.drop(columns='pendidikan')\n",
    "df_test['pendidikan_encoded'] = label_encoder.fit_transform(df_test['pendidikan'])\n",
    "df_test =df_test.drop(columns='pendidikan')\n",
    "\n",
    "df_train_feature['status_pernikahan_encoded'] = label_encoder.fit_transform(df_train_feature['status_pernikahan'])\n",
    "df_train_feature =df_train_feature.drop(columns='status_pernikahan')\n",
    "df_test['status_pernikahan_encoded'] = label_encoder.fit_transform(df_test['status_pernikahan'])\n",
    "df_test =df_test.drop(columns='status_pernikahan')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bin edges and labels\n",
    "bin_edges = [1890, 1920, 1940, 1960, 1980, 2000, 2010]\n",
    "bin_labels = ['0', '1', '2', '3', '4', '5']\n",
    "\n",
    "# Perform binning\n",
    "df_train_feature['tahun_kelahiran_binned'] = pd.cut(df_train_feature['tahun_kelahiran'], bins=bin_edges, labels=bin_labels)\n",
    "df_train_feature.drop(columns='tahun_kelahiran', inplace=True)\n",
    "df_test['tahun_kelahiran_binned'] = pd.cut(df_test['tahun_kelahiran'], bins=bin_edges, labels=bin_labels)\n",
    "df_test.drop(columns='tahun_kelahiran', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Feature  Importance\n",
      "0                  pendapatan    0.150370\n",
      "5              belanja_daging    0.116151\n",
      "3            terakhir_belanja    0.095650\n",
      "4                belanja_buah    0.093883\n",
      "7                 belanja_kue    0.093829\n",
      "6                belanja_ikan    0.093479\n",
      "9               pembelian_web    0.072439\n",
      "10             pembelian_toko    0.071748\n",
      "8            pembelian_diskon    0.059096\n",
      "13  status_pernikahan_encoded    0.043209\n",
      "12         pendidikan_encoded    0.042171\n",
      "14     tahun_kelahiran_binned    0.029991\n",
      "2          jumlah_anak_remaja    0.019906\n",
      "1          jumlah_anak_balita    0.017139\n",
      "11                    keluhan    0.000938\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Memisahkan fitur dan label\n",
    "X = df_train_feature\n",
    "y = df_train_label['jumlah_promosi']\n",
    "\n",
    "# Melatih model Random Forest untuk menentukan feature importance\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Mendapatkan feature importance\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Menampilkan feature importance\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feature = df_train_feature.drop(columns={'keluhan', 'jumlah_anak_balita', 'jumlah_anak_remaja'})\n",
    "df_test = df_test.drop(columns={'keluhan', 'jumlah_anak_balita', 'jumlah_anak_remaja'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hakim\\AppData\\Local\\Temp\\ipykernel_12008\\1465589498.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[data < lower_bound] = lower_bound\n",
      "C:\\Users\\Hakim\\AppData\\Local\\Temp\\ipykernel_12008\\1465589498.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[data > upper_bound] = upper_bound\n"
     ]
    }
   ],
   "source": [
    "def handle_outliers_iqr(data):\n",
    "    # Calculate quartiles\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Calculate lower and upper bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Handle outliers\n",
    "    # Replace outliers with the upper or lower bound\n",
    "    data[data < lower_bound] = lower_bound\n",
    "    data[data > upper_bound] = upper_bound\n",
    "    \n",
    "    return data\n",
    "\n",
    "for column in df_train_feature.select_dtypes(include=np.number):\n",
    "    if column != 'jumlah_promosi':\n",
    "        df_train_feature[column] = handle_outliers_iqr(df_train_feature[column])\n",
    "        df_test[column] = handle_outliers_iqr(df_test[column])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Membuat objek SimpleImputer untuk data pelatihan dengan strategi 'median'\n",
    "imputer_median = SimpleImputer(strategy='median')\n",
    "\n",
    "# Mengisi nilai yang hilang dalam data pelatihan dengan strategi 'median'\n",
    "df_train_features_imputed = pd.DataFrame(imputer_median.fit_transform(df_train_feature), columns=df_train_feature.columns)\n",
    "\n",
    "# Membuat objek SimpleImputer untuk data pengujian dengan strategi 'most_frequent'\n",
    "imputer_most_frequent = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Mengambil kolom 'ID' dari df_test\n",
    "df_test_id = df_test['ID']\n",
    "\n",
    "# Menghapus kolom 'ID' dari df_test\n",
    "df_test_features = df_test.drop('ID', axis=1)\n",
    "\n",
    "# Melakukan imputasi nilai yang hilang dalam data pengujian kecuali pada kolom 'ID' dengan strategi 'most_frequent'\n",
    "df_test_features_imputed = pd.DataFrame(imputer_median.fit_transform(df_test_features), columns=df_test_features.columns)\n",
    "\n",
    "# Menggabungkan kembali kolom 'ID' dengan data yang telah diimputasi\n",
    "df_test_imputed = pd.concat([df_test_id, df_test_features_imputed], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3818 entries, 0 to 3817\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   ID                         3818 non-null   int64  \n",
      " 1   pendapatan                 3818 non-null   float64\n",
      " 2   terakhir_belanja           3818 non-null   float64\n",
      " 3   belanja_buah               3818 non-null   float64\n",
      " 4   belanja_daging             3818 non-null   float64\n",
      " 5   belanja_ikan               3818 non-null   float64\n",
      " 6   belanja_kue                3818 non-null   float64\n",
      " 7   pembelian_diskon           3818 non-null   float64\n",
      " 8   pembelian_web              3818 non-null   float64\n",
      " 9   pembelian_toko             3818 non-null   float64\n",
      " 10  pendidikan_encoded         3818 non-null   float64\n",
      " 11  status_pernikahan_encoded  3818 non-null   float64\n",
      " 12  tahun_kelahiran_binned     3818 non-null   float64\n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 387.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_test_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pendapatan</th>\n",
       "      <th>terakhir_belanja</th>\n",
       "      <th>belanja_buah</th>\n",
       "      <th>belanja_daging</th>\n",
       "      <th>belanja_ikan</th>\n",
       "      <th>belanja_kue</th>\n",
       "      <th>pembelian_diskon</th>\n",
       "      <th>pembelian_web</th>\n",
       "      <th>pembelian_toko</th>\n",
       "      <th>pendidikan_encoded</th>\n",
       "      <th>status_pernikahan_encoded</th>\n",
       "      <th>tahun_kelahiran_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115621394.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>50575.0</td>\n",
       "      <td>260967.0</td>\n",
       "      <td>50575.0</td>\n",
       "      <td>20230.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84063000.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6069.0</td>\n",
       "      <td>44506.0</td>\n",
       "      <td>80920.0</td>\n",
       "      <td>20230.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127532564.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>117611.0</td>\n",
       "      <td>265460.0</td>\n",
       "      <td>96341.0</td>\n",
       "      <td>145573.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165579620.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>206346.0</td>\n",
       "      <td>1613901.0</td>\n",
       "      <td>27725.0</td>\n",
       "      <td>125868.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117703159.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>90563.0</td>\n",
       "      <td>311757.0</td>\n",
       "      <td>40358.0</td>\n",
       "      <td>33875.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3812</th>\n",
       "      <td>78199470.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6069.0</td>\n",
       "      <td>25977.0</td>\n",
       "      <td>3856.0</td>\n",
       "      <td>5784.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>109306000.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50575.0</td>\n",
       "      <td>36054.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>104621000.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>62713.0</td>\n",
       "      <td>8092.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3815</th>\n",
       "      <td>110850000.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>18207.0</td>\n",
       "      <td>70805.0</td>\n",
       "      <td>24276.0</td>\n",
       "      <td>27795.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>130512000.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>329749.0</td>\n",
       "      <td>600831.0</td>\n",
       "      <td>420784.0</td>\n",
       "      <td>161840.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3817 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pendapatan  terakhir_belanja  belanja_buah  belanja_daging  \\\n",
       "0     115621394.0              47.0       50575.0        260967.0   \n",
       "1      84063000.0              70.0        6069.0         44506.0   \n",
       "2     127532564.0              45.0      117611.0        265460.0   \n",
       "3     165579620.0              90.0      206346.0       1613901.0   \n",
       "4     117703159.0              78.0       90563.0        311757.0   \n",
       "...           ...               ...           ...             ...   \n",
       "3812   78199470.0              33.0        6069.0         25977.0   \n",
       "3813  109306000.0              44.0           0.0         50575.0   \n",
       "3814  104621000.0              68.0        2023.0         62713.0   \n",
       "3815  110850000.0              67.0       18207.0         70805.0   \n",
       "3816  130512000.0              70.0      329749.0        600831.0   \n",
       "\n",
       "      belanja_ikan  belanja_kue  pembelian_diskon  pembelian_web  \\\n",
       "0          50575.0      20230.0               2.0            2.0   \n",
       "1          80920.0      20230.0               9.0            6.0   \n",
       "2          96341.0     145573.0               1.0            1.0   \n",
       "3          27725.0     125868.0               0.0            7.0   \n",
       "4          40358.0      33875.0               7.0            6.0   \n",
       "...            ...          ...               ...            ...   \n",
       "3812        3856.0       5784.0               5.0            1.0   \n",
       "3813       36054.5          0.0               3.0            6.0   \n",
       "3814        8092.0          0.0               7.0            5.0   \n",
       "3815       24276.0      27795.0               4.0            5.0   \n",
       "3816      420784.0     161840.0               3.0            7.0   \n",
       "\n",
       "      pembelian_toko  pendidikan_encoded  status_pernikahan_encoded  \\\n",
       "0                5.0                 5.0                        4.0   \n",
       "1                4.0                 5.0                        4.0   \n",
       "2                7.0                 5.0                        3.0   \n",
       "3                8.0                 2.0                        4.0   \n",
       "4                5.0                 5.0                        4.0   \n",
       "...              ...                 ...                        ...   \n",
       "3812             0.0                 2.0                        3.0   \n",
       "3813             3.0                 1.0                        4.0   \n",
       "3814             7.0                 2.0                        3.0   \n",
       "3815             4.0                 3.0                        4.0   \n",
       "3816            15.0                 5.0                        3.0   \n",
       "\n",
       "      tahun_kelahiran_binned  \n",
       "0                        3.0  \n",
       "1                        2.0  \n",
       "2                        3.0  \n",
       "3                        3.0  \n",
       "4                        3.0  \n",
       "...                      ...  \n",
       "3812                     2.0  \n",
       "3813                     2.0  \n",
       "3814                     3.0  \n",
       "3815                     2.0  \n",
       "3816                     3.0  \n",
       "\n",
       "[3817 rows x 12 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_features_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train_features_imputed, df_train_label, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['jumlah_promosi']\n",
    "y_test = y_test['jumlah_promosi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # minmax = MinMaxScaler()\n",
    "\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# # X_train = minmax.fit_transform(X_train)\n",
    "\n",
    "# # X_test = minmax.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(764, 12)\n",
      "(3053, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF, Gradien Boost, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Inisialisasi model XGBoost Classifier\n",
    "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score Macro untuk Random Forest Classifier: 0.7403617986550357\n",
      "F1-score Macro untuk Gradient Boosting Classifier: 0.548972729577926\n",
      "F1-score Macro untuk XGBClassifier: 0.6386640250683814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Evaluasi kinerja Random Forest Classifier\n",
    "f1_macro_rf = f1_score(y_test, y_pred_rf, average='macro')\n",
    "print(\"F1-score Macro untuk Random Forest Classifier:\", f1_macro_rf)\n",
    "\n",
    "# Evaluasi kinerja Gradient Boosting Classifier\n",
    "f1_macro_gb = f1_score(y_test, y_pred_gb, average='macro')\n",
    "print(\"F1-score Macro untuk Gradient Boosting Classifier:\", f1_macro_gb)\n",
    "\n",
    "# Evaluasi kinerja XGradient Boosting Classifier\n",
    "f1_macro_xgb = f1_score(y_test, y_pred_xgb, average='macro')\n",
    "print(\"F1-score Macro untuk XGBClassifier:\", f1_macro_xgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross val for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores - Random Forest: [0.71065029 0.68373639 0.69817947 0.66825047 0.70219745]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Cross-validation untuk Random Forest\n",
    "cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"Cross-Validation Scores - Random Forest:\", cv_scores_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# # \n",
    "# # Inisialisasi model Random Forest Classifier\n",
    "# rf_model = RandomForestClassifier()\n",
    "\n",
    "# # Lakukan cross-validation dengan F1-score macro sebagai metrik evaluasi\n",
    "# f1_scores = cross_val_score(rf_model, X_train, y_train, cv=10, scoring='f1_macro')\n",
    "\n",
    "# # Cetak hasil cross-validation\n",
    "# print(\"F1-scores setiap fold:\", f1_scores)\n",
    "# print(\"Rata-rata F1-score:\", f1_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Terbaik: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "F1-score Macro setelah GridSearchCV: 0.7274826934053304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "#deafult\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params_rf = grid_search.best_params_\n",
    "print(\"Parameter Terbaik:\", best_params_rf)\n",
    "\n",
    "y_pred_grid = grid_search.predict(X_test)\n",
    "f1_macro_grid = f1_score(y_test, y_pred_grid, average='macro')\n",
    "print(\"F1-score Macro setelah GridSearchCV:\", f1_macro_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Terbaik: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "F1-score Macro setelah GridSearchCV: 0.718212171292575\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Inisialisasi model XGBoost Classifier\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "# Definisikan grid hyperparameter yang ingin Anda telusuri\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Inisialisasi objek GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(xgb_model, param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Lakukan penyetelan hyperparameter pada data pelatihan\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Cetak parameter terbaik yang ditemukan\n",
    "best_params_xgb = grid_search.best_params_\n",
    "print(\"Parameter Terbaik:\", best_params_xgb)\n",
    "\n",
    "# Evaluasi kinerja model menggunakan parameter terbaik pada data pengujian\n",
    "y_pred_grid_xgb = grid_search_xgb.predict(X_test)\n",
    "f1_macro_grid_xgb = f1_score(y_test, y_pred_grid_xgb, average='macro')\n",
    "print(\"F1-score Macro setelah GridSearchCV:\", f1_macro_grid_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hakim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [13:06:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"min_samples_leaf\", \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hakim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [13:07:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"min_samples_leaf\", \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hakim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [13:07:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"min_samples_leaf\", \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hakim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [13:07:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"min_samples_leaf\", \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hakim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [13:07:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"min_samples_leaf\", \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hakim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [13:07:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"min_samples_leaf\", \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score Macro untuk Stacking Classifier: 0.7482061921068949\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Meta-model dan base-models\n",
    "meta_model = LogisticRegression()\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(**best_params_rf, random_state=42)),\n",
    "    ('xgb', XGBClassifier(**best_params_xgb, random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# Membuat Stacking Classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Latih Stacking Classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi dan evaluasi\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluasi dengan F1-score Macro\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"F1-score Macro untuk Stacking Classifier:\", f1_macro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n",
    "submission_data = df_test_imputed.drop(columns='ID')\n",
    "submission['jumlah_promosi'] = stacking_clf.predict(submission_data)\n",
    "submission.to_csv('../submissions/coba2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1316\n",
       "1     294\n",
       "2     303\n",
       "3     462\n",
       "4     524\n",
       "5     575\n",
       "6     344\n",
       "Name: jumlah_promosi, dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBMIT_PATH = '../submissions/submission_stacking.csv'\n",
    "\n",
    "csv = pd.read_csv(SUBMIT_PATH)\n",
    "category_counts = csv['jumlah_promosi'].value_counts().sort_index()\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1244\n",
       "1     343\n",
       "2     296\n",
       "3     478\n",
       "4     543\n",
       "5     585\n",
       "6     329\n",
       "Name: jumlah_promosi, dtype: int64"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBMIT_PATH = '../submissions/coba2.csv'\n",
    "\n",
    "csv = pd.read_csv(SUBMIT_PATH)\n",
    "category_counts = csv['jumlah_promosi'].value_counts().sort_index()\n",
    "category_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
