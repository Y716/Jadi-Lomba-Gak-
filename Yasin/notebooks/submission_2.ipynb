{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "pGEGh2lOXnTJ",
        "outputId": "cf2f5bc7-23fc-4421-a68e-7510d63f9566"
      },
      "outputs": [],
      "source": [
        "# Pake yang ini\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import f1_score\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from fast_ml.model_development import train_valid_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_FEATURE_PATH = r'../../Datasets/train_features.csv'\n",
        "TRAIN_LABEL_PATH = r'../../Datasets/train_labels.csv'\n",
        "TEST_PATH = r'../../Datasets/test_features.csv'\n",
        "SAMPLE_SUBMISSION_PATH = r\"../../Datasets/submission_format.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_feature_dat = pd.read_csv(TRAIN_FEATURE_PATH)\n",
        "train_label_dat = pd.read_csv(TRAIN_LABEL_PATH)\n",
        "test_dat = pd.read_csv(TEST_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3817 entries, 0 to 3816\n",
            "Data columns (total 16 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   tahun_kelahiran          3817 non-null   int64  \n",
            " 1   pendidikan               3628 non-null   object \n",
            " 2   status_pernikahan        3605 non-null   object \n",
            " 3   pendapatan               3627 non-null   float64\n",
            " 4   jumlah_anak_balita       3627 non-null   float64\n",
            " 5   jumlah_anak_remaja       3613 non-null   float64\n",
            " 6   terakhir_belanja         3645 non-null   float64\n",
            " 7   belanja_buah             3636 non-null   float64\n",
            " 8   belanja_daging           3639 non-null   float64\n",
            " 9   belanja_ikan             3624 non-null   float64\n",
            " 10  belanja_kue              3603 non-null   float64\n",
            " 11  pembelian_diskon         3639 non-null   float64\n",
            " 12  pembelian_web            3652 non-null   float64\n",
            " 13  pembelian_toko           3648 non-null   float64\n",
            " 14  keluhan                  3621 non-null   float64\n",
            " 15  tanggal_menjadi_anggota  1065 non-null   object \n",
            "dtypes: float64(12), int64(1), object(3)\n",
            "memory usage: 477.2+ KB\n"
          ]
        }
      ],
      "source": [
        "train_feature_dat.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Prep\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {},
      "outputs": [],
      "source": [
        "#drop tanggal_menjadi_anggota\n",
        "train_feature_dat = train_feature_dat.drop(columns={'tanggal_menjadi_anggota', 'belanja_buah', 'belanja_daging', 'belanja_ikan', 'belanja_kue'})\n",
        "test_dat = test_dat.drop(columns={'tanggal_menjadi_anggota', 'belanja_buah', 'belanja_daging', 'belanja_ikan', 'belanja_kue'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Null Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3817 entries, 0 to 3816\n",
            "Data columns (total 11 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   tahun_kelahiran     3817 non-null   int64  \n",
            " 1   pendidikan          3817 non-null   object \n",
            " 2   status_pernikahan   3817 non-null   object \n",
            " 3   pendapatan          3817 non-null   float64\n",
            " 4   jumlah_anak_balita  3817 non-null   float64\n",
            " 5   jumlah_anak_remaja  3817 non-null   float64\n",
            " 6   terakhir_belanja    3817 non-null   float64\n",
            " 7   pembelian_diskon    3817 non-null   float64\n",
            " 8   pembelian_web       3817 non-null   float64\n",
            " 9   pembelian_toko      3817 non-null   float64\n",
            " 10  keluhan             3817 non-null   float64\n",
            "dtypes: float64(8), int64(1), object(2)\n",
            "memory usage: 328.1+ KB\n"
          ]
        }
      ],
      "source": [
        "# fill all null values\n",
        "train_feature_dat.fillna(train_feature_dat.mean(), inplace=True)\n",
        "test_dat.fillna(test_dat.mean(), inplace=True)\n",
        "\n",
        "train_feature_dat.fillna(train_feature_dat.mode().iloc[0], inplace=True)\n",
        "test_dat.fillna(test_dat.mode().iloc[0], inplace=True)\n",
        "train_feature_dat.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outlier Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {},
      "outputs": [],
      "source": [
        "#windsorizer\n",
        "def windsorize_by_percentage(data, lower_percentile, upper_percentile):\n",
        "    lower_bound = np.percentile(data, lower_percentile)\n",
        "    upper_bound = np.percentile(data, upper_percentile)\n",
        "    windsorized_data = []\n",
        "    for value in data:\n",
        "        if value < lower_bound:\n",
        "            windsorized_data.append(lower_bound)\n",
        "        elif value > upper_bound:\n",
        "            windsorized_data.append(upper_bound)\n",
        "        else:\n",
        "            windsorized_data.append(value)\n",
        "\n",
        "    return windsorized_data\n",
        "\n",
        "# Specify lower and upper percentiles\n",
        "lower_percentile = 10\n",
        "upper_percentile = 90\n",
        "\n",
        "for column in train_feature_dat.select_dtypes(include=np.number):\n",
        "    train_feature_dat[column] = windsorize_by_percentage(train_feature_dat[column], lower_percentile, upper_percentile)\n",
        "    test_dat[column] = windsorize_by_percentage(test_dat[column], lower_percentile, upper_percentile)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### One hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Perform one-hot encoding\n",
        "# train_dat = pd.get_dummies(train_dat, columns=['attribute_0', 'attribute_1'])\n",
        "# test_dat = pd.get_dummies(test_dat, columns=['attribute_0', 'attribute_1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "train_feature_dat['pendidikan_encoded'] = label_encoder.fit_transform(train_feature_dat['pendidikan'])\n",
        "train_feature_dat =train_feature_dat.drop(columns='pendidikan')\n",
        "test_dat['pendidikan_encoded'] = label_encoder.fit_transform(test_dat['pendidikan'])\n",
        "test_dat =test_dat.drop(columns='pendidikan')\n",
        "\n",
        "train_feature_dat['status_pernikahan_encoded'] = label_encoder.fit_transform(train_feature_dat['status_pernikahan'])\n",
        "train_feature_dat =train_feature_dat.drop(columns='status_pernikahan')\n",
        "test_dat['status_pernikahan_encoded'] = label_encoder.fit_transform(test_dat['status_pernikahan'])\n",
        "test_dat =test_dat.drop(columns='status_pernikahan')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Binning Tahun Kelahiran"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define bin edges and labels\n",
        "bin_edges = [1890, 1920, 1940, 1960, 1980, 2000, 2010]\n",
        "bin_labels = ['0', '1', '2', '3', '4', '5']\n",
        "\n",
        "# Perform binning\n",
        "train_feature_dat['tahun_kelahiran_binned'] = pd.cut(train_feature_dat['tahun_kelahiran'], bins=bin_edges, labels=bin_labels)\n",
        "train_feature_dat.drop(columns='tahun_kelahiran', inplace=True)\n",
        "test_dat['tahun_kelahiran_binned'] = pd.cut(test_dat['tahun_kelahiran'], bins=bin_edges, labels=bin_labels)\n",
        "test_dat.drop(columns='tahun_kelahiran', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SPLIT TRAIN AND TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {
        "id": "mSRiKNXrb47c"
      },
      "outputs": [],
      "source": [
        "# Train test split\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_feature_dat, train_label_dat, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FEATURE SCALING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {
        "id": "6ozDzrB8bh0e"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ozhFADaeMUr",
        "outputId": "7717c149-903b-4b60-915b-b938f2522695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2671, 11)\n",
            "(1146, 11)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "    print(\"F1 Score  :\", f1_score(y_true, y_pred, average='macro'))\n",
        "\n",
        "def train_eval_models(models: dict, X_train, X_test, y_train, y_test):\n",
        "    for model in models:\n",
        "        m = model\n",
        "        m.fit(X_train, y_train)\n",
        "        y_pred = m.predict(X_test)\n",
        "        print(model.__class__.__name__, models[model])\n",
        "        metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score  : 0.4456452066031247\n"
          ]
        }
      ],
      "source": [
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test)\n",
        "metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradient Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score  : 0.5201611475817621\n"
          ]
        }
      ],
      "source": [
        "gdb = GradientBoostingClassifier()\n",
        "gdb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = gdb.predict(X_test)\n",
        "metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 347,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score  : 0.6229039311228196\n"
          ]
        }
      ],
      "source": [
        "xgboost = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "xgboost.fit(X_train, y_train)\n",
        "\n",
        "y_pred = xgboost.predict(X_test)\n",
        "metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kaggle Submission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {},
      "outputs": [],
      "source": [
        "submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n",
        "test_dat.drop(columns='ID', inplace=True)\n",
        "submission['jumlah_promosi'] = xgboost.predict(test_dat)\n",
        "submission.to_csv('../submissions/testing_3.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iFPNmVB20MRF"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
